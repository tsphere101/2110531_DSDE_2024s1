{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKq5vgbI3QOi"
   },
   "source": [
    "##**Assignment 3 (2023/2): ML1**\n",
    "**Safe to eat or deadly poison?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtWlAnW-4IIw"
   },
   "source": [
    "This homework is a classification task to identify whether a mushroom is edible or poisonous.\n",
    "\n",
    "This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981).\n",
    "\n",
    "Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the credibility of a mushroom; no rule like \"leaflets three, let it be'' for Poisonous Oak and Ivy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia90I1DY4hYT"
   },
   "source": [
    "Step 1. Load 'mushroom2020_dataset.csv' data from the “Attachment” (note: this data set has been preliminarily prepared.).\n",
    "\n",
    "Step 2. Drop rows where the target (label) variable is missing.\n",
    "\n",
    "Step 3. Drop the following variables:\n",
    "'id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'\n",
    "\n",
    "Step 4. Examine the number of rows, the number of digits, and whether any are missing.\n",
    "\n",
    "Step 5. Fill missing values by adding the mean for numeric variables and the mode for nominal variables.\n",
    "\n",
    "Step 6. Convert the label variable e (edible) to 1 and p (poisonous) to 0 and check the quantity. class0: class1\n",
    "\n",
    "Step 7. Convert the nominal variable to numeric using a dummy code with drop_first = True.\n",
    "\n",
    "Step 8. Split train/test with 20% test, stratify, and seed = 2020.\n",
    "\n",
    "Step 9. Create a Random Forest with GridSearch on training data with 5 CV with n_jobs=-1.\n",
    "\t'criterion':['gini','entropy']\n",
    "'max_depth': [2,3]\n",
    "'min_samples_leaf':[2,5]\n",
    "'N_estimators':[100]\n",
    "'random_state': 2020\n",
    "\n",
    "Step 10.  Predict the testing data set with classification_report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEoNW_114VQh"
   },
   "source": [
    "**Complete class MushroomClassifier from given code template below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-Xw2UEzU3s0k"
   },
   "outputs": [],
   "source": [
    "#import your other libraries here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "j59N5vzD3P1Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "class MushroomClassifier:\n",
    "    def __init__(self, data_path): # DO NOT modify this line\n",
    "        self.data_path = data_path\n",
    "        self.df = pd.read_csv(data_path)\n",
    "\n",
    "    def Q1(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            1. (From step 1) Before doing the data prep., how many \"na\" are there in \"gill-size\" variables?\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        return df['gill-size'].isna().sum()\n",
    "\n",
    "\n",
    "    def Q2(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            2. (From step 2-4) How many rows of data, how many variables?\n",
    "            - Drop rows where the target (label) variable is missing.\n",
    "            - Drop the following variables:\n",
    "            'id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate','stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'\n",
    "            - Examine the number of rows, the number of digits, and whether any are missing.\n",
    "        \"\"\"\n",
    "        columns_to_remove = [\n",
    "            'id',\n",
    "            'gill-attachment',\n",
    "            'gill-spacing',\n",
    "            'gill-size',\n",
    "            'gill-color-rate',\n",
    "            'stalk-root',\n",
    "            'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring',\n",
    "            'stalk-color-above-ring-rate',\n",
    "            'stalk-color-below-ring-rate',\n",
    "            'veil-color-rate',\n",
    "            'veil-type',\n",
    "        ]\n",
    "        def drop_label_na(df):\n",
    "            return df[df['label'].notna()]\n",
    "        def remove_columns(df,columns_to_remove):\n",
    "            return df.drop(columns=columns_to_remove)\n",
    "        self.df =  (df\n",
    "               .pipe(drop_label_na)\n",
    "               .pipe(remove_columns,columns_to_remove)\n",
    "                   )\n",
    "        return self.df.shape\n",
    "\n",
    "\n",
    "    def Q3(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            3. (From step 5-6) Answer the quantity class0:class1\n",
    "            - Fill missing values by adding the mean for numeric variables and the mode for nominal variables.\n",
    "            - Convert the label variable e (edible) to 1 and p (poisonous) to 0 and check the quantity. class0: class1\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.compose import ColumnTransformer \n",
    "        from sklearn.preprocessing import FunctionTransformer\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        def label_encoder(column):\n",
    "            encode_map = {'e':1,'p':0}\n",
    "            return column.apply(lambda row : row.apply(lambda label : encode_map[label]) ,axis=1)\n",
    "\n",
    "        df = self.df\n",
    "        label_column = ['label']\n",
    "        categorial_columns = df.iloc[:,1:-1].columns\n",
    "        numerical_columns = ['cap-color-rate']\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('label_encoding',Pipeline(steps=[\n",
    "                    ('label_encoder',FunctionTransformer(func=label_encoder, validate=False)),\n",
    "                ]),label_column),\n",
    "                ('categorial_imputation',Pipeline(steps=[\n",
    "                    ('mode_imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                ]),categorial_columns),\n",
    "                ('numerical-imputation',Pipeline(steps=[\n",
    "                    ('mean_imputer',SimpleImputer(strategy='mean'))\n",
    "                ]),numerical_columns),\n",
    "            ],\n",
    "            remainder='passthrough',\n",
    "        )\n",
    "        preprocessor.fit(df)\n",
    "        preprocessed_dataframe = pd.DataFrame(preprocessor.transform(df),columns=df.columns)\n",
    "        self.df = preprocessed_dataframe\n",
    "        \n",
    "        return preprocessed_dataframe.label.value_counts()\n",
    "\n",
    "\n",
    "    def Q4(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            4. (From step 7-8) How much is each training and testing sets\n",
    "            - Convert the nominal variable to numeric using a dummy code with drop_first = True.\n",
    "            - Split train/test with 20% test, stratify, and seed = 2020.\n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        preprocessed_dataframe = self.df\n",
    "        categorial_columns = self.df.iloc[:,1:-1].columns\n",
    "        one_hot_encode_pipeline = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('onehot',OneHotEncoder(drop='first',sparse_output=False),categorial_columns)\n",
    "            ],\n",
    "            remainder='passthrough',\n",
    "            force_int_remainder_cols=False,\n",
    "        )\n",
    "        X_features = preprocessed_dataframe.drop('label',axis=1)\n",
    "        y = preprocessed_dataframe['label']\n",
    "        one_hot_encode_pipeline.fit(X_features)\n",
    "        encoded_columns = one_hot_encode_pipeline.named_transformers_['onehot'].get_feature_names_out()\n",
    "        X = one_hot_encode_pipeline.transform(X_features)\n",
    "        \n",
    "        X_train,X_test, y_train,y_test =train_test_split(X,y,stratify=y,test_size=0.2,random_state=2020)\n",
    "        \n",
    "        return X_train.shape, X_test.shape\n",
    "\n",
    "\n",
    "    def Q5(self):\n",
    "        \"\"\"\n",
    "            5. (From step 9) Best params after doing random forest grid search.\n",
    "            Create a Random Forest with GridSearch on training data with 5 CV with n_jobs=-1.\n",
    "            - 'criterion':['gini','entropy']\n",
    "            - 'max_depth': [2,3]\n",
    "            - 'min_samples_leaf':[2,5]\n",
    "            - 'N_estimators':[100]\n",
    "            - 'random_state': 2020\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        pass\n",
    "\n",
    "\n",
    "    def Q6(self):\n",
    "        \"\"\"\n",
    "            5. (From step 10) What is the value of macro f1 (Beware digit !)\n",
    "            Predict the testing data set with confusion_matrix and classification_report,\n",
    "            using scientific rounding (less than 0.5 dropped, more than 0.5 then increased)\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        pass\n",
    "\n",
    "    def pipelining(self):\n",
    "        df = self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('mushroom2020_dataset.csv')\n",
    "\n",
    "def dataframe_prep(df):\n",
    "    df = df_original\n",
    "    columns_to_remove = [\n",
    "            'id',\n",
    "            'gill-attachment',\n",
    "            'gill-spacing',\n",
    "            'gill-size',\n",
    "            'gill-color-rate',\n",
    "            'stalk-root',\n",
    "            'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring',\n",
    "            'stalk-color-above-ring-rate',\n",
    "            'stalk-color-below-ring-rate',\n",
    "            'veil-color-rate',\n",
    "            'veil-type',\n",
    "    ]    \n",
    "\n",
    "    drop_columns = Pipeline(steps=[\n",
    "        ('drop_columns', FunctionTransformer(func=lambda df : df.drop(columns=columns_to_remove), validate=False))\n",
    "    ])\n",
    "    \n",
    "    def drop_nan_rows(X, column_name):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.dropna(subset=[column_name])\n",
    "        else:\n",
    "            raise TypeError(f\"Input must be a pandas DataFrame : input is {type(X)}\")\n",
    "    label_column = 'label'\n",
    "    drop_target_missing = Pipeline(steps=[\n",
    "        ('drop_na_label',FunctionTransformer(func=lambda df : drop_nan_rows(df,label_column),validate=False)),\n",
    "    ])\n",
    "    def encode_label_to_binary(df,column):\n",
    "        encode_map = {'e':1, 'p':0}\n",
    "        newdf = df.copy()\n",
    "        newdf[column] = newdf[column].map(encode_map).astype(float)\n",
    "        return newdf\n",
    "    encode_label_to_binary_tranformer = FunctionTransformer(func=lambda df : encode_label_to_binary(df,label_column),validate=False)\n",
    "    label_transformer = Pipeline(steps=[\n",
    "        ('encode_label_to_binary',encode_label_to_binary_tranformer),\n",
    "    ])\n",
    "    col_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('label_transformer',label_transformer,[label_column])\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "    )\n",
    "\n",
    "    drop_columns_and_missing_row_pipe = Pipeline(steps=[\n",
    "        ('drop_target_missing',drop_target_missing),\n",
    "        ('drop_columns',drop_columns),\n",
    "        ('col_transformer',col_transformer),\n",
    "    ])\n",
    "    result = drop_columns_and_missing_row_pipe.fit_transform(df)\n",
    "    left_over_columns = [column for column in df.columns if column not in columns_to_remove]\n",
    "    \n",
    "    df = pd.DataFrame(result, columns=left_over_columns)\n",
    "    \n",
    "    # norminal_columns_loc = [dataframe.columns.get_loc(column) for column in dataframe.iloc[:,1:-1].columns]\n",
    "    norminal_columns = ['cap-shape', 'cap-surface', 'bruises', 'odor', 'stalk-shape',\n",
    "       'ring-number', 'ring-type', 'spore-print-color', 'population',\n",
    "       'habitat']\n",
    "    numeric_columns= ['cap-color-rate']\n",
    "    \n",
    "    fill_mean_pipe = Pipeline(steps=[\n",
    "        ('fill_mean', SimpleImputer(strategy='mean')),\n",
    "    ])\n",
    "    fill_mode_pipe = Pipeline(steps=[\n",
    "        ('fill_mode', SimpleImputer(strategy='most_frequent'))\n",
    "    ])\n",
    "    identity_transformer = FunctionTransformer(func=lambda X : X, validate=False)\n",
    "    impute_columns = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('identity', identity_transformer,[label_column]),\n",
    "            ('impute_mode_to_norminal_columns',fill_mode_pipe,norminal_columns),\n",
    "            ('impute_mean_to_numeric_columns',fill_mean_pipe,numeric_columns),\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(impute_columns.fit_transform(df),columns=df.columns)\n",
    "\n",
    "    ohe_pipe = ColumnTransformer(\n",
    "        transformers=[\n",
    "             ('label_identity',identity_transformer,[label_column]),\n",
    "             ('onehot',OneHotEncoder(drop='first',sparse_output=False),categorial_columns),\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "    )\n",
    "\n",
    "    ohe_pipe.fit(df)\n",
    "    final_preprocessed = pd.DataFrame(ohe_pipe.transform(df),columns=['label',*ohe_pipe.named_transformers_['onehot'].get_feature_names_out(), 'cap-color-rate'])\n",
    "    return final_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4611, 42) (4611,)\n",
      "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 100, 'random_state': 2020}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       732\n",
      "           1       0.95      0.98      0.97       421\n",
      "\n",
      "    accuracy                           0.98      1153\n",
      "   macro avg       0.97      0.98      0.97      1153\n",
      "weighted avg       0.98      0.98      0.98      1153\n",
      "\n",
      "[[712  20]\n",
      " [  8 413]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def split(df):\n",
    "    X = df.drop(columns=['label'])\n",
    "    y = df['label'].astype(int)\n",
    "    X_train,X_test,y_train,y_test= train_test_split(X,y,stratify=y,random_state=2020,test_size=0.2)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def train(df):\n",
    "    X_train,X_test,y_train,y_test=split(df)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    param_grid = {\n",
    "        'criterion':['gini','entropy'],\n",
    "        'max_depth':[2,3],\n",
    "        'min_sampe_leaf':[2,5],\n",
    "    }\n",
    "\n",
    "def search_best_param(df):\n",
    "    X_train,X_test,y_train,y_test=split(df)\n",
    "    clf = RandomForestClassifier()\n",
    "    param_grid = {\n",
    "        'criterion':['gini','entropy'],\n",
    "        'max_depth':[2,3],\n",
    "        'min_samples_leaf':[2,5],\n",
    "        'n_estimators':[100],\n",
    "        'random_state': [2020],\n",
    "    }\n",
    "    grid_search = GridSearchCV(param_grid=param_grid,estimator=clf,n_jobs=-1,cv=5)\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    return grid_search\n",
    "\n",
    "dfx = dataframe_prep(df)\n",
    "dfx['cap-color-rate'] = dfx['cap-color-rate'].astype(float)\n",
    "X_train,X_test,y_train,y_test = split(dfx)\n",
    "grid_search = search_best_param(dfx)\n",
    "\n",
    "report = classification_report(y_test,grid_search.predict(X_test),digits=2)\n",
    "cmatrix = confusion_matrix(y_test,grid_search.predict(X_test))\n",
    "print(grid_search.best_params_)\n",
    "print(report)\n",
    "print(cmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "macBnE5U5KYm"
   },
   "source": [
    "Run the code below to only test that your code can work, and there is no need to submit it to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "eGpwReMy3NCI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "(5764, 12)\n",
      "label\n",
      "0    3660\n",
      "1    2104\n",
      "Name: count, dtype: int64\n",
      "((4611, 42), (1153, 42))\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    hw = MushroomClassifier('mushroom2020_dataset.csv')\n",
    "    return (hw.Q1(),hw.Q2(),hw.Q3(),hw.Q4(),hw.Q5(),hw.Q6())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('mushroom2020_dataset.csv')\n",
    "    for ans in main():\n",
    "        print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'id',\n",
    "    'gill-attachment',\n",
    "    'gill-spacing',\n",
    "    'gill-size',\n",
    "    'gill-color-rate',\n",
    "    'stalk-root',\n",
    "    'stalk-surface-above-ring',\n",
    "    'stalk-surface-below-ring',\n",
    "    'stalk-color-above-ring-rate',\n",
    "    'stalk-color-below-ring-rate',\n",
    "    'veil-color-rate',\n",
    "    'veil-type',\n",
    "]\n",
    "def flat(xs):\n",
    "    return sum(xs,[])\n",
    "def drop_label_na(df):\n",
    "    return df[df.label.notna()]\n",
    "def remove_columns(df,columns_to_remove):\n",
    "    return df.drop(columns=columns_to_remove)\n",
    "def fill_mean_for_numeric_types(df):\n",
    "    columns = flat([[column] if pd.api.types.is_numeric_dtype(df[column]) else [] for column in df.columns])\n",
    "    return df\n",
    "    \n",
    "dff = (df\n",
    ".pipe(drop_label_na)\n",
    ".pipe(remove_columns,columns_to_remove) \n",
    "      )\n",
    "numeric_df = dff.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "      <th>cap-color-rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label cap-shape cap-surface bruises odor stalk-shape ring-number ring-type  \\\n",
       "0   0.0         x           s       t    p           e           o         p   \n",
       "1   1.0         x           s       t    a           e           o         p   \n",
       "2   1.0         b           s       t    l           e           o         p   \n",
       "3   0.0         x           y       t    p           e           o         p   \n",
       "4   1.0         x           s       f    n           t           o         e   \n",
       "\n",
       "  spore-print-color population habitat cap-color-rate  \n",
       "0                 k          s       u            1.0  \n",
       "1                 n          n       g            2.0  \n",
       "2                 n          n       m            3.0  \n",
       "3                 k          s       u            3.0  \n",
       "4                 n          a       g            4.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def label_encoder(column):\n",
    "    encode_map = {'e':1.0,'p':0.0}\n",
    "    return column.apply(lambda row : row.apply(lambda label : encode_map[label]) ,axis=1)\n",
    "\n",
    "label_column = ['label']\n",
    "categorial_columns = dff.iloc[:,1:-1].columns\n",
    "numerical_columns = ['cap-color-rate']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('label_encoding',Pipeline(steps=[\n",
    "            ('label_encoder',FunctionTransformer(func=label_encoder, validate=False)),\n",
    "        ]),label_column),\n",
    "        ('categorial_imputation',Pipeline(steps=[\n",
    "            ('mode_imputer',SimpleImputer(strategy='most_frequent')),\n",
    "        ]),categorial_columns),\n",
    "        ('numerical-imputation',Pipeline(steps=[\n",
    "            ('mean_imputer',SimpleImputer(strategy='mean'))\n",
    "        ]),numerical_columns),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    ")\n",
    "preprocessor.fit(dff)\n",
    "preprocessed_dataframe = pd.DataFrame(preprocessor.transform(dff),columns=dff.columns)\n",
    "preprocessed_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4611, 42), (1153, 42))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "one_hot_encode_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot',OneHotEncoder(drop='first',sparse_output=False),categorial_columns)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False,\n",
    ")\n",
    "X_features = preprocessed_dataframe.drop('label',axis=1)\n",
    "y = preprocessed_dataframe['label'].astype(float)\n",
    "one_hot_encode_pipeline.fit(X_features)\n",
    "encoded_columns = one_hot_encode_pipeline.named_transformers_['onehot'].get_feature_names_out()\n",
    "X = one_hot_encode_pipeline.transform(X_features)\n",
    "\n",
    "X_train,X_test, y_train,y_test =train_test_split(X,y,stratify=y,test_size=0.2,random_state=2020)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 2, 'n_estimators': 100, 'random_state': 2020}\n",
      "Best score: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# model_pipeline = Pipeline(\n",
    "#     [\n",
    "#         ('clf', RandomForestClassifier()),\n",
    "#     ]\n",
    "# )\n",
    "# param_grid = {\n",
    "#     'clf__criterion' : ['gini', 'entropy'],\n",
    "#     'clf__max_depth' : [2,3],\n",
    "#     'clf__min_samples_leaf' : [2,5],\n",
    "#     'clf__n_estimators' : [100],\n",
    "#     'clf__random_state' : [2020],\n",
    "# }\n",
    "# grid_search = GridSearchCV(param_grid=param_grid,estimator=model_pipeline,n_jobs=-1)\n",
    "# grid_search.fit(X_train,y_train)\n",
    "# print(f'Best parameters: {grid_search.best_params_}')\n",
    "# print(f'Best score: {grid_search.best_score_:.2f}')\n",
    "clf = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[2,3],\n",
    "    'min_samples_leaf':[2,5],\n",
    "    'n_estimators':[100],\n",
    "    'random_state':[2020],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    n_jobs=-1,\n",
    "    param_grid=param_grid,\n",
    "    estimator=clf,\n",
    ")\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best score: {grid_search.best_score_:.2f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
